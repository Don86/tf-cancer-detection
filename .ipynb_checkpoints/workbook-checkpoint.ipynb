{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "220025\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# TF learn imports\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "\n",
    "# Define some constants\n",
    "TRAIN_DIR = \"./data/train\"\n",
    "TEST_DIR = \"./data//test\"\n",
    "IMG_WIDTH = 64 # all images will be made square\n",
    "LR = 1e-3 #learning rate\n",
    "\n",
    "#MODEL_NAME = \"cats-v-dogs-{}.model\".format(\"conv6\")\n",
    "#print(\"MODEL_NAME = %s\" % MODEL_NAME)\n",
    "\n",
    "dm = pd.read_csv(\"./data/train_labels.csv\")\n",
    "print(len(dm))\n",
    "\n",
    "# ========= Some helper functions =========\n",
    "def normalize_img(img):\n",
    "    \"\"\"Normalizes an image to \n",
    "    \n",
    "    PARAMS\n",
    "    ------\n",
    "    img: array of shape: (width, height, 3)\n",
    "    \n",
    "    RETURNS\n",
    "    -------\n",
    "    img_n: array of shape: (width, height, 3), normalized between 0 and 1\n",
    "    \"\"\"\n",
    "    img_n = np.zeros(img.shape)\n",
    "    for c_channel in range(3):\n",
    "        channel_array = img[:, :, c_channel]/255\n",
    "        img_n[:, :, c_channel] = channel_array\n",
    "    \n",
    "    return img_n\n",
    "\n",
    "\n",
    "def create_train_data(save_fn):\n",
    "    \"\"\"Does k-fold. \n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for fn in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        full_fn = TRAIN_DIR+\"/\"+fn\n",
    "        img = cv2.resize(normalize_img(cv2.imread(full_fn)), (IMG_WIDTH, IMG_WIDTH))\n",
    "        label = dm.loc[dm[\"id\"]==fn.split(\".\")[0]].label.values[0]\n",
    "        \n",
    "        training_data.append([fn, np.array(img), label])\n",
    "    \n",
    "    #df = pd.DataFrame(data=training_data, columns=[\"filename\", \"data\", \"label\"])\n",
    "    #if len(save_fn) > 0:\n",
    "    #    df.to_pickle(save_fn)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220025/220025 [1:26:49<00:00, 42.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pre-process and save training data\n",
    "train_data = create_train_data(\"all-data-df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=training_data, columns=[\"filename\", \"data\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=train_data, columns=[\"img_data\", \"label\"])\n",
    "d0 = df.loc[df[\"label\"]==[1, 0]]\n",
    "d1 = df.loc[df[\"label\"]==[0, 1]]\n",
    "\n",
    "d0_test = d0.head(300)\n",
    "train_names_ls = []\n",
    "for nm in list(df[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = create_train_data()\n",
    "# Otherwise, if already created:\n",
    "train_data = np.load(TRAIN_DIR+\"/train_data.npy\")\n",
    "print(\"Num. of records = \", len(train_data))\n",
    "# Each row is of length 2; row[0] = image data, row[1] = one-hot encoded label\n",
    "\n",
    "# Grab training and testing subsets\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "# Get array of images...\n",
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_WIDTH, IMG_WIDTH, 1)\n",
    "# ...and their labels\n",
    "Y = np.array([i[1] for i in train])\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_WIDTH, IMG_WIDTH, 1)\n",
    "# ...and their labels\n",
    "test_y = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and fit\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_WIDTH, IMG_WIDTH, 3], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 2048, activation='relu')\n",
    "convnet = dropout(convnet, 0.5)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, \n",
    "                     optimizer='adam', \n",
    "                     learning_rate=LR, \n",
    "                     loss='categorical_crossentropy', \n",
    "                     name='targets')\n",
    "\n",
    "# the 2nd param logs tensorboard to /tmp\n",
    "model = tflearn.DNN(convnet, tensorboard_dir=\"summaries\")\n",
    "\n",
    "t0 = time.time()\n",
    "# Note: run_id is for tensorboard later\n",
    "model.fit({'input': X}, {'targets': Y}, \n",
    "          n_epoch=5, \n",
    "          validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "          snapshot_step=500, \n",
    "          show_metric=True, \n",
    "          run_id=\"prod-run\")\n",
    "\n",
    "print(\"Done in %.2fs\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
